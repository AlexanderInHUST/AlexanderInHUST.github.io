\chapter{Conclusion and Future work}
\label{sec_5}

This thesis explores a specific type of AI processor, the Huawei Ascend, by proposing two hardware-aware optimization solutions tailored to its architecture. Through detailed benchmarking, we analyze hardware characteristics and develop a performance model that provides insights into its operation (Chapter \ref{sec_2}). Subsequently, two main optimization strategies are introduced: (1) replacing inefficient scalar or vectorized operations with alternative implementations (Chapter \ref{sec_3}), and (2) using matrix multiplications as substitutes for scalar or vectorized operations (Chapter \ref{sec_4}). These findings offer an in-depth examination of current AI processors, shedding light on their strengths and limitations, opportunities for algorithmic optimizations, and directions for future hardware improvements. The primary results and contributions of this work are as follows:

\textbf{First, an accurate performance model is constructed based on detailed dissections of the Huawei Ascend processors.}
Alongside general hardware unit benchmarks, the analysis focuses specifically on bus contention, which significantly influences the runtime behavior of IO operations. Using the collected hardware parameters, the performance model, named Verrocchio, takes program source code as input to accurately predict execution time. Benchmark results also highlight a key design trade-off in AI processors: optimized matrix multiplication performance comes at the expense of scalar and vector operation efficiency.

This trade-off presents a significant challenge when migrating algorithms from other platforms. While AI processors substantially accelerate matrix multiplications, full AI applications generally require other essential operations, such as scalar or vector operations for dynamic addressing or activations. Thus, two main approaches are proposed to alleviate these bottlenecks.

\textbf{(1) The first approach replaces inefficient scalar and vector operations with alternative implementations.}
Taking SelB-\textit{k}-NN as an example, we aim to replace the most computationally expensive scalar operations and vector comparisons \& selections with optimized vectorized operations on Huawei Ascend processors. This approach not only replaces inefficient operations but also enhances the programmability of AI processors. For instance, on AI processors lacking specific \verb|vecCmp| and \verb|vecSel| hardware support, this approach suggests a \verb|ReLU|-based bitwise algorithm as a substitute.

This approach delivers significant performance gains in our experiments. However, it does not leverage the primary hardware feature of AI processors, the Matrix MACs. Consequently, it could be applied across different platforms following extensive benchmarking. To address this, we propose the second approach, which is specifically optimized for AI processors.

\textbf{(2) The second approach maps scalar and vector operations to matrix multiplications on Matrix MACs.}
The Cube-fx method exemplifies this approach, utilizing the Matrix MACs for computations that do not typically involve matrix multiplication. Since matrix multiplications inherently include additional mapping and reduction steps compared to vector operations, Cube-fx applies this feature to map single inputs across multiple functions for Taylor expansion and reduce each multiplication result to produce the final polynomial output.

Compared to the first approach, this second approach fully utilizes the Matrix MACs, leading to substantial performance gains specific to AI processor hardware. However, it is applicable to a more limited range of applications. The primary challenge lies in the Matrix MACs' restricted functionality, as they only perform multiply-and-add operations. While some applications, such as Cube-fx proposed in this thesis, can be adapted to these operations, others requiring more complex operations (e.g., logical operations, exponentiation) cannot be easily transformed. Therefore, both approaches are necessary for algorithm optimizations on the current AI processors. Together, these two strategies provide a comprehensive solution that addresses both general-purpose and MAC-specific optimization needs.

Furthermore, at the software level, while traditional optimization methods (e.g., instruction scheduling or data reuse) remain valuable, further software optimizations on current AI processor architectures are expected to be feasible only for specific, narrow application cases. Future work should therefore prioritize the evolution of next-generation hardware architectures to achieve broader and more effective optimizations.

A promising direction involves advancements in the architecture of Matrix MACs. Initial work by Zhang et al. \cite{10.1145/3470496.3527411} has begun to address this by proposing a novel hardware unit to perform operations of the form $(A \odot B \oplus C)$. This unit allows programmers to customize operations, selecting specific $\odot$ and $\oplus$ operations suited to their algorithms. While this is a significant step, more complex applications will require core computations that go beyond two binary operations. Thus, our future work will focus on enhancing Matrix MACs within next-generation AI processors to support higher degrees of customization and programmability, enabling more complex and varied algorithmic implementations. Such advancements are expected to expand the range of AI applications that can be efficiently supported, further pushing the boundaries of AI processor capabilities.

In addition, a more accurate performance modeling framework beyond traditional Big O notation will be explored. Since Big O notation does not capture low-level hardware behavior or instruction-level inefficiencies, an extension of the Roofline model \cite{DBLP:journals/cacm/WilliamsWP09} is proposed. This extended model will incorporate multiple rooflines representing different hardware units (e.g., vector units, scalar units, memory bandwidth), offering a more detailed and architecture-aware performance visualization. With such a model, it will be possible to analyze algorithms not only by their theoretical complexity, but also by their interaction with heterogeneous hardware resources, thereby guiding software, hardware co-optimization more effectively.